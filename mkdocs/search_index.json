{
    "docs": [
        {
            "location": "/", 
            "text": "FaceSwap Documentation\n\n\nFaceSwap is used to demonstrate the critical role cloudlets play in shortening end-to-end latency for computation offloading mobile applications. \n\n\nFaceSwap demo consists of a front-end Android client and a back-end server performing.\n\n\nDemo Video\n\n\n\n\nFaceSwap Android Client\n\n\nFaceSwap Android client is available on Google Play:\n\n\n\n\nYou can also directly download the apk \nhere\n. To install this apk directly through adb, follow this \nguide\n.\n\n\nFaceSwap Server Setup\n\n\nUse Pre-Packaged Images\n\n\nCloudlet Setup\n\n\nThe FaceSwap server is wrapped into a qcow2 virtual machine disk image. You can download it \nhere\n. \n\n\nMethod 1 OpenStack:\n\n\n\n\nImport the qcow2 image into a running OpenStack following this \nguide\n.\n\n\nLaunch that instance. FaceSwap server will automatically launch at start-up time.\n\n\nAfter the instance has fully booted up, connect FaceSwap client to it for use. (see \nUser Guide\n)\n\n\n\n\nMethod 2 KVM/QEMU\n\n\nYou can also directly create a virtual machine from the qcow2 image using KVM/QEMU. \n\n\n\n\nFor ubuntu, you can install KVM/QEMU following \nhere\n. \n\n\n\n\nModify this \nfaceswap-server.xml\n to point to the downloaded path of your image. For instance, if the downloaded faceswap-server-release.qcow is at /home/junjuew/faceswap-server-release.qcow. Then the xml file should be modified into:\n\n\n  ...\n  \ndisk type='file' device='disk'\n\n   \ndriver name='qemu' type='qcow2'/\n\n   \nsource file='/home/junjuew/faceswap-setup/faceswap-server-release.qcow'/\n\n   \ntarget dev='vda' bus='virtio'/\n\n  \n/disk\n\n  ...\n\n\n\n\n\n\n\nLaunch the virtual machine:\n\n\nsudo virsh create faceswap-server.xml\n\n\n\n\n\n\n\nThe cloudlet image takes a bit longer to be fully booted up and initialized. You can monitor whether the virtual machine has fully booted up by checking whether you've arrived at log-in shell through virt-manager console.\n\n\n\n\nConnect FaceSwap client to it for use. (see \nUser Guide\n). \n\n\n\n\nCloud Setup\n\n\n\n\nFind FaceSwap Android server disk image on Amazon EC2 Oregon/Ireland. The AMI ID in EC2 Oregon is \nami-31c43351\n. The AMI ID in EC2 Ireland is \nami-b0abc7c3\n. The AMI name is \nFaceSwap-server-release\n. \n\n\nCreate an instance from the AMI. The recommended EC2 instance types are m4.large, m4.xlarge, and more powerful ones.\n\n\nConfigure security group associated with that instance to open port \n9098, 9101\n for inbound TCP traffic. \n\n\nLaunch that instance. FaceSwap server will automatically launch at start-up time.\n\n\nAfter the instance has fully booted up, connect FaceSwap client to it for use. (see \nUser Guide\n)\n\n\n\n\nAccess Disk Image Content\n\n\nIf you want to customize the content of the image, the default username:password is \nfaceswap-admin:faceswap-admin\n. You're advised to change the password as soon as you gain access.\n\n\nThe log file of FaceSwap is at /var/log/FaceSwap.log\n\n\nBy Hand\n\n\nThese instructions are based on ubuntu 14.04. \n\n\n\n\n\n\nInstall OpenFace and its dependency by hand. See \nguide\n\n\n\n\n\n\nDownload this Gabriel \nrelease\n. Install its dependency and gabriel:\n\n\n    sudo apt-get install -y gcc python-dev default-jre python-pip pssh python-psutil \n\n    sudo pip install \\\n            Flask==0.9 \\\n            Flask-RESTful \\\n            Jinja2==2.8 \\\n            MarkupSafe==0.23 \\\n            pycrypto \\\n            six \\\n            Werkzeug==0.11.10 \n\n    wget https://github.com/cmusatyalab/gabriel/archive/mobisys2016submission.zip \n\n    sudo apt-get install -y unzip \n\n    unzip mobisys2016submission.zip \n\n    cd gabriel-mobisys2016submission \n\n    sudo python setup.py install\n\n\n\n\n\n\n\nDownload FaceSwap \nsource code\n. Install its dependency and start it by invoking server/start_demo\n\n\n    mkdir faceswap \n\n    cd faceswap \n\n    wget https://github.com/cmusatyalab/faceswap/archive/v1.0.zip \n\n    unzip v1.0.zip \n\n    cd ./faceswap-1.0/server/ \n\n    sudo pip install \\\n      websocket-client==0.35.0 \\\n      autobahn==0.10.4 \\\n      imagehash==1.0 \\\n      twisted==15.2.1 \\\n      scipy==0.14 \\\n      scikit-learn==0.17 \\\n      protobuf==2.5 \n    ./start_demo\n\n\n\nIf you didn't install Torch at ~/torch, please edit server/start_demo.sh to source torch-activate at your installed location at line 6.\n\n\n\n\n\n\nTo stop demo use server/kill_demo.sh\n\n\n\n\n\n\nSource Code\n\n\nThe source code is available \nhere\n.\n\n\nHardware Requirements\n\n\nThe recommended FaceSwap server should have 4 core and 8GM RAM.", 
            "title": "Home"
        }, 
        {
            "location": "/#faceswap-documentation", 
            "text": "FaceSwap is used to demonstrate the critical role cloudlets play in shortening end-to-end latency for computation offloading mobile applications.   FaceSwap demo consists of a front-end Android client and a back-end server performing.", 
            "title": "FaceSwap Documentation"
        }, 
        {
            "location": "/#demo-video", 
            "text": "", 
            "title": "Demo Video"
        }, 
        {
            "location": "/#faceswap-android-client", 
            "text": "FaceSwap Android client is available on Google Play:   You can also directly download the apk  here . To install this apk directly through adb, follow this  guide .", 
            "title": "FaceSwap Android Client"
        }, 
        {
            "location": "/#faceswap-server-setup", 
            "text": "", 
            "title": "FaceSwap Server Setup"
        }, 
        {
            "location": "/#use-pre-packaged-images", 
            "text": "", 
            "title": "Use Pre-Packaged Images"
        }, 
        {
            "location": "/#cloudlet-setup", 
            "text": "The FaceSwap server is wrapped into a qcow2 virtual machine disk image. You can download it  here .", 
            "title": "Cloudlet Setup"
        }, 
        {
            "location": "/#method-1-openstack", 
            "text": "Import the qcow2 image into a running OpenStack following this  guide .  Launch that instance. FaceSwap server will automatically launch at start-up time.  After the instance has fully booted up, connect FaceSwap client to it for use. (see  User Guide )", 
            "title": "Method 1 OpenStack:"
        }, 
        {
            "location": "/#method-2-kvmqemu", 
            "text": "You can also directly create a virtual machine from the qcow2 image using KVM/QEMU.    For ubuntu, you can install KVM/QEMU following  here .    Modify this  faceswap-server.xml  to point to the downloaded path of your image. For instance, if the downloaded faceswap-server-release.qcow is at /home/junjuew/faceswap-server-release.qcow. Then the xml file should be modified into:    ...\n   disk type='file' device='disk' \n    driver name='qemu' type='qcow2'/ \n    source file='/home/junjuew/faceswap-setup/faceswap-server-release.qcow'/ \n    target dev='vda' bus='virtio'/ \n   /disk \n  ...    Launch the virtual machine:  sudo virsh create faceswap-server.xml    The cloudlet image takes a bit longer to be fully booted up and initialized. You can monitor whether the virtual machine has fully booted up by checking whether you've arrived at log-in shell through virt-manager console.   Connect FaceSwap client to it for use. (see  User Guide ).", 
            "title": "Method 2 KVM/QEMU"
        }, 
        {
            "location": "/#cloud-setup", 
            "text": "Find FaceSwap Android server disk image on Amazon EC2 Oregon/Ireland. The AMI ID in EC2 Oregon is  ami-31c43351 . The AMI ID in EC2 Ireland is  ami-b0abc7c3 . The AMI name is  FaceSwap-server-release .   Create an instance from the AMI. The recommended EC2 instance types are m4.large, m4.xlarge, and more powerful ones.  Configure security group associated with that instance to open port  9098, 9101  for inbound TCP traffic.   Launch that instance. FaceSwap server will automatically launch at start-up time.  After the instance has fully booted up, connect FaceSwap client to it for use. (see  User Guide )", 
            "title": "Cloud Setup"
        }, 
        {
            "location": "/#access-disk-image-content", 
            "text": "If you want to customize the content of the image, the default username:password is  faceswap-admin:faceswap-admin . You're advised to change the password as soon as you gain access.  The log file of FaceSwap is at /var/log/FaceSwap.log", 
            "title": "Access Disk Image Content"
        }, 
        {
            "location": "/#by-hand", 
            "text": "These instructions are based on ubuntu 14.04.     Install OpenFace and its dependency by hand. See  guide    Download this Gabriel  release . Install its dependency and gabriel:      sudo apt-get install -y gcc python-dev default-jre python-pip pssh python-psutil  \n    sudo pip install \\\n            Flask==0.9 \\\n            Flask-RESTful \\\n            Jinja2==2.8 \\\n            MarkupSafe==0.23 \\\n            pycrypto \\\n            six \\\n            Werkzeug==0.11.10  \n    wget https://github.com/cmusatyalab/gabriel/archive/mobisys2016submission.zip  \n    sudo apt-get install -y unzip  \n    unzip mobisys2016submission.zip  \n    cd gabriel-mobisys2016submission  \n    sudo python setup.py install    Download FaceSwap  source code . Install its dependency and start it by invoking server/start_demo      mkdir faceswap  \n    cd faceswap  \n    wget https://github.com/cmusatyalab/faceswap/archive/v1.0.zip  \n    unzip v1.0.zip  \n    cd ./faceswap-1.0/server/  \n    sudo pip install \\\n      websocket-client==0.35.0 \\\n      autobahn==0.10.4 \\\n      imagehash==1.0 \\\n      twisted==15.2.1 \\\n      scipy==0.14 \\\n      scikit-learn==0.17 \\\n      protobuf==2.5 \n    ./start_demo  If you didn't install Torch at ~/torch, please edit server/start_demo.sh to source torch-activate at your installed location at line 6.    To stop demo use server/kill_demo.sh", 
            "title": "By Hand"
        }, 
        {
            "location": "/#source-code", 
            "text": "The source code is available  here .", 
            "title": "Source Code"
        }, 
        {
            "location": "/#hardware-requirements", 
            "text": "The recommended FaceSwap server should have 4 core and 8GM RAM.", 
            "title": "Hardware Requirements"
        }, 
        {
            "location": "/user-guide/", 
            "text": "FaceSwap Android Client User Guide\n\n\nBefore using FaceSwap Android client, please make sure all FaceSwap backend server has been started\n\n\n1. Add FaceSwap Server IPs:\n\n\nClick on Menu Button on the top right corner and select 'Manage Servers'. \nFill in the name and ip address. Select the server's category (\"cloudlet\" or \"cloud\") for easy-of-management.\n\n\n       \n\n\n2. Select a specific server by type and name\n\n\n3. Add Training Images (3 different methods)\n\n\n\n\nCollect Images: Open smartphone camera to collect training images\n\n\nFrom Local File: Load a FaceSwap dataset from local directory\n\n\nFrom Google Drive: Load a FaceSwap dataset from Google Drive\n\n\n\n\n4. Choose faces to substitude:\n\n\nThe substituded face is the processed image. The different between the substituded face and the original face is the end-to-end latency.\nFor example, in below image, the person on the left is being substituded by the face of the person on the right. \nThe face overlay on the left is a delayed face image from the face on the right. \nThe total delay time is the end-to-end latency of the system.\n\n\n       \n\n\n5. Run Demo\n\n\nFaceSwap Server User Guide\n\n\nFaceSwap Android server is available on Amazon EC2. The AMI name is \"FaceSwap-server-release\". The AMI ID in EC2 Oregon is ami-31c43351.\n\n\nTo use the image, simply start a server from the AMI. The recommended Amazon instance is m4.large. FaceSwap backend will automatically start itself once the image is booted.", 
            "title": "User Guide"
        }, 
        {
            "location": "/user-guide/#faceswap-android-client-user-guide", 
            "text": "Before using FaceSwap Android client, please make sure all FaceSwap backend server has been started", 
            "title": "FaceSwap Android Client User Guide"
        }, 
        {
            "location": "/user-guide/#1-add-faceswap-server-ips", 
            "text": "Click on Menu Button on the top right corner and select 'Manage Servers'. \nFill in the name and ip address. Select the server's category (\"cloudlet\" or \"cloud\") for easy-of-management.", 
            "title": "1. Add FaceSwap Server IPs:"
        }, 
        {
            "location": "/user-guide/#2-select-a-specific-server-by-type-and-name", 
            "text": "", 
            "title": "2. Select a specific server by type and name"
        }, 
        {
            "location": "/user-guide/#3-add-training-images-3-different-methods", 
            "text": "Collect Images: Open smartphone camera to collect training images  From Local File: Load a FaceSwap dataset from local directory  From Google Drive: Load a FaceSwap dataset from Google Drive", 
            "title": "3. Add Training Images (3 different methods)"
        }, 
        {
            "location": "/user-guide/#4-choose-faces-to-substitude", 
            "text": "The substituded face is the processed image. The different between the substituded face and the original face is the end-to-end latency.\nFor example, in below image, the person on the left is being substituded by the face of the person on the right. \nThe face overlay on the left is a delayed face image from the face on the right. \nThe total delay time is the end-to-end latency of the system.", 
            "title": "4. Choose faces to substitude:"
        }, 
        {
            "location": "/user-guide/#5-run-demo", 
            "text": "", 
            "title": "5. Run Demo"
        }, 
        {
            "location": "/user-guide/#faceswap-server-user-guide", 
            "text": "FaceSwap Android server is available on Amazon EC2. The AMI name is \"FaceSwap-server-release\". The AMI ID in EC2 Oregon is ami-31c43351.  To use the image, simply start a server from the AMI. The recommended Amazon instance is m4.large. FaceSwap backend will automatically start itself once the image is booted.", 
            "title": "FaceSwap Server User Guide"
        }, 
        {
            "location": "/dev-guide/", 
            "text": "FaceSwap Architecture\n\n\n\n\nFaceSwap Android client continously streams 640x480 images from the smartphone to the backend.\n\n\nAt backend, a three-tier hierarchy of face tracking, face detection, and \nOpenFace\n-based face recognition is employed. For each frame, once the face tracking result is available, bounding boxes and compressed pixels (JPEG) of all faces are then returned. Face detection and face recognition run outside of the critical path and opportunistically update trackers once their results become available. \n\n\nFrom our experience, face detection and face recognition combined takes around \n200ms\n while face tracking takes around \n15ms\n. By using face tracking to mask long latencies of face detection and face recognition, we are able to achieve a higher frame rate.\n\n\nOffload Latency Comparision\n\n\n\n\nHere is a cumulative distribution function (CDF) graph of offload latencies when the offload site is a cloudlet or a cloud (Amazon EC2 Oregon). The offload latency is the sum of the network transmission time and server computation time. \n\n\nTiming Breakdown\n\n\n\n\nHere is a timing breakdown that explains the difference between cloudlet offload latency and cloud offload latency. Though the cloud has a shorter computation time due to a more powerful virtual machine, the cloudlet greatly reduces network latency. Image compression and rendering on mobile devices consume the same amount of time for both cases, therefore not contributing to the latency difference.", 
            "title": "Architecture"
        }, 
        {
            "location": "/dev-guide/#faceswap-architecture", 
            "text": "FaceSwap Android client continously streams 640x480 images from the smartphone to the backend.  At backend, a three-tier hierarchy of face tracking, face detection, and  OpenFace -based face recognition is employed. For each frame, once the face tracking result is available, bounding boxes and compressed pixels (JPEG) of all faces are then returned. Face detection and face recognition run outside of the critical path and opportunistically update trackers once their results become available.   From our experience, face detection and face recognition combined takes around  200ms  while face tracking takes around  15ms . By using face tracking to mask long latencies of face detection and face recognition, we are able to achieve a higher frame rate.", 
            "title": "FaceSwap Architecture"
        }, 
        {
            "location": "/dev-guide/#offload-latency-comparision", 
            "text": "Here is a cumulative distribution function (CDF) graph of offload latencies when the offload site is a cloudlet or a cloud (Amazon EC2 Oregon). The offload latency is the sum of the network transmission time and server computation time.", 
            "title": "Offload Latency Comparision"
        }, 
        {
            "location": "/dev-guide/#timing-breakdown", 
            "text": "Here is a timing breakdown that explains the difference between cloudlet offload latency and cloud offload latency. Though the cloud has a shorter computation time due to a more powerful virtual machine, the cloudlet greatly reduces network latency. Image compression and rendering on mobile devices consume the same amount of time for both cases, therefore not contributing to the latency difference.", 
            "title": "Timing Breakdown"
        }, 
        {
            "location": "/faq/", 
            "text": "I'm getting \"Illegal instruction (core dumped)\" in my log file\n\n\nIt's likely that your cpu doesn't support AVX instruction. dlib uses AVX to make face detection faster. To check if AVX instruction is available on your machine, use\n\n\n       grep avx /proc/cpuinfo\n\n\n\nTo resolve this problem:\n\n\nMethod 1\n\n\nUse an AVX enabled machine\n\n\nMethod 2\n\n\nIf you are using the pre-packaged image, uninstall dlib first using\n\n\n         sudo rm /usr/local/lib/python2.7/dist-packages/dlib.so\n\n\n\nThen install dlib using pip:\n\n\n         sudo pip install dlib\n\n\n\nI'm getting following ferror when using server/start_demo.sh\n\n\n\n\n    \"\nurlopen error [Errno 111] Connection refused\n\"\n\n    \"failed to register UCOMM to control\"\n\n\n\n\n\nTo resolve this problem:\nEdit line 29 \"sleep 5\" in server/start_demo.sh to a sleep longer time, for example, \"sleep 15\". \nChanging the sleep time to a larger value gives one of gabriel server more time to boot up. The original sleep time may not be enough if you are running the server on a slow virtual machine.", 
            "title": "FAQ"
        }, 
        {
            "location": "/faq/#im-getting-illegal-instruction-core-dumped-in-my-log-file", 
            "text": "It's likely that your cpu doesn't support AVX instruction. dlib uses AVX to make face detection faster. To check if AVX instruction is available on your machine, use         grep avx /proc/cpuinfo  To resolve this problem:", 
            "title": "I'm getting \"Illegal instruction (core dumped)\" in my log file"
        }, 
        {
            "location": "/faq/#method-1", 
            "text": "Use an AVX enabled machine", 
            "title": "Method 1"
        }, 
        {
            "location": "/faq/#method-2", 
            "text": "If you are using the pre-packaged image, uninstall dlib first using           sudo rm /usr/local/lib/python2.7/dist-packages/dlib.so  Then install dlib using pip:           sudo pip install dlib", 
            "title": "Method 2"
        }, 
        {
            "location": "/faq/#im-getting-following-ferror-when-using-serverstart_demosh", 
            "text": "\" urlopen error [Errno 111] Connection refused \"\n\n    \"failed to register UCOMM to control\"   To resolve this problem:\nEdit line 29 \"sleep 5\" in server/start_demo.sh to a sleep longer time, for example, \"sleep 15\". \nChanging the sleep time to a larger value gives one of gabriel server more time to boot up. The original sleep time may not be enough if you are running the server on a slow virtual machine.", 
            "title": "I'm getting following ferror when using server/start_demo.sh"
        }
    ]
}